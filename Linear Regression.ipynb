{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "handed-marshall",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "empirical-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the NumPy library, commonly used for numerical operations on arrays\n",
    "import numpy as np\n",
    "\n",
    "# Importing the train_test_split function from scikit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importing the datasets module from scikit-learn, which contains various example datasets\n",
    "from sklearn import datasets\n",
    "\n",
    "# Importing the Matplotlib library's pyplot module, commonly used for plotting and visualizing data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Import the mean_squared_error and r2_score metrics from scikit-learn for model evaluation\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Import the LinearRegression model from scikit-learn to perform linear regression\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prepared-incident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1) (100,)\n"
     ]
    }
   ],
   "source": [
    "# Generating a synthetic regression dataset with 100 samples and 1 feature using make_regression from scikit-learn\n",
    "# - n_samples=100: Specifies the number of samples\n",
    "# - n_features=1: Specifies the number of features (independent variables)\n",
    "# - noise=20: Adds Gaussian noise to the output to simulate real-world data\n",
    "# - random_state=4: Sets a seed for reproducibility of the dataset\n",
    "X, y = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)\n",
    "\n",
    "# Printing the shape of the feature matrix X and the target vector y\n",
    "# X.shape should output (100, 1) indicating 100 samples with 1 feature\n",
    "# y.shape should output (100,) indicating 100 target values\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mathematical-mineral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fdb48d9f208>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating a new figure for plotting with a specified size of 8x5 inches\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Plotting a scatter plot using Matplotlib\n",
    "# - X[:,0]: Selects the first (and only) feature from the dataset X for the x-axis\n",
    "# - y: The target values on the y-axis\n",
    "# - color='b': Sets the color of the scatter plot points to blue\n",
    "# - marker='o': Uses a circle ('o') marker for each point\n",
    "# - s=30: Sets the size of the markers to 30\n",
    "plt.scatter(X[:,0], y, color='b', marker='o', s=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-deviation",
   "metadata": {},
   "source": [
    "## Model Using Sklearn Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "varying-fusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [75.05935146]\n",
      "Intercept: -0.1424160855882628\n",
      "Mean squared error: 305.7741316228642\n",
      "Coefficient of determination (R^2 score): 0.9247515208302274\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "\n",
    "# Create a LinearRegression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"Mean squared error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"Coefficient of determination (R^2 score):\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-charm",
   "metadata": {},
   "source": [
    "### Hypothesis: $h(x) = wx + b$ \n",
    "Our target is to minimize the error between the predicted value $h(x)$ and the actual value $y$. <br> \n",
    "### $\\binom{minimize}{w, b} = (h(x) - y))^2$ <br>\n",
    "\n",
    "This formula is valid for a single feature (input variable), so we have one weight $w$ and one bias $b$. However, in the case of multiple features, $w$ becomes a vector of weights, each corresponding to a different feature.\n",
    "### The cost function $J(w,b) = \\frac{1}{2n}\\sum_{i=1}^{n}(h(x_i)-y_i)^{2}$\n",
    "where:\n",
    "- $n$ is the number of training examples.\n",
    "- $h(x_i)$ is the predicted value for the $i$-th training example.\n",
    "- $y_i$ is the actual value for the $i$-th training example.\n",
    "\n",
    "\n",
    "### Gradient discent\n",
    "![](gradient-descent.png)\n",
    "Gradient discent to minimize the cost function $J(w, b)$. To do that, we are going to repeateadly update the $w$ and $b$ until convergence using the following formula:\n",
    "### $dw = \\frac{1}{n}\\sum_{i=1}^{n} (h(x_i) - y_i)\\cdot x_i$\n",
    "### $db = \\frac{1}{n}\\sum_{i=1}^{n} (h(x_i) - y_i)$\n",
    "### Update rule\n",
    "The weights $w$ and bias $b$ are updated using the following rules:\n",
    "### $w = w - \\alpha * dw$\n",
    "### $b = b - \\alpha * db$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-resource",
   "metadata": {},
   "source": [
    "## Model From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "binding-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, lr=0.001, n_iters=1000):\n",
    "        # Initialize the learning rate and the number of iterations\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        \n",
    "        # Initialize weights and bias as None; they will be set in the fit method\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Get the number of samples and features from the input data\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Initialize weights as a zero array with the same length as the number of features\n",
    "        # Initialize bias as 0\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # Perform gradient descent for the specified number of iterations\n",
    "        for _ in range(self.n_iters):\n",
    "            # Calculate the linear hypothesis (predictions): hx = X * weights + bias\n",
    "            hx = np.dot(X, self.weights) + self.bias\n",
    "            \n",
    "            # Compute the gradients for weights and bias\n",
    "            dw = (1/n_samples) * np.dot(X.T, (hx - y))\n",
    "            db = (1/n_samples) * np.sum(hx - y)\n",
    "            \n",
    "            # Update weights and bias using gradient descent\n",
    "            # temp1 = self.weights - self.lr * dw\n",
    "            # temp2 = self.bias - self.lr * db\n",
    "            # self.weights = temp1\n",
    "            # self.bias = temp2\n",
    "            \n",
    "            # Alternatively, the weights and bias can be updated directly as follows:\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "            \n",
    "    def predict(self, X):\n",
    "        # Make predictions using the learned weights and bias\n",
    "        hx = np.dot(X, self.weights) + self.bias\n",
    "        return hx            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-president",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spatial-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "# X_train and y_train are the features and target variable for the training set\n",
    "# X_test and y_test are the features and target variable for the testing set\n",
    "# test_size=0.2 means 20% of the data will be used for testing, and 80% for training\n",
    "# random_state=1234 ensures reproducibility of the split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1234)\n",
    "\n",
    "# Create an instance of the LinearRegression class with a learning rate of 0.01\n",
    "regressor = LinearRegression(lr=0.01)\n",
    "\n",
    "# Train the linear regression model using the training data (X_train, y_train)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-boulder",
   "metadata": {},
   "source": [
    "### $\\text{mse} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "applied-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_predicted):\n",
    "    # Calculate the Mean Squared Error (MSE)\n",
    "    # The difference between the true values (y_true) and the predicted values (y_predicted) is squared\n",
    "    # The mean of these squared differences is then returned as the MSE\n",
    "    return np.mean((y_true - y_predicted)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "verified-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained linear regression model to make predictions on the test data\n",
    "# The predict method applies the learned weights and bias to the features in X_test\n",
    "predicted = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vietnamese-privacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 305.7719958301902\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Mean Squared Error (MSE) between the actual values (y_test) and the predicted values (predicted)\n",
    "# Print the calculated MSE value\n",
    "print(\"Mean squared error:\", mse(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-binding",
   "metadata": {},
   "source": [
    "## Plot The Decision Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure for plotting with a specified size (width=8, height=6)\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "# Use the trained model to make predictions for the entire dataset X\n",
    "# This is used to plot the regression line\n",
    "y_pred_line = regressor.predict(X)\n",
    "\n",
    "# Plot the training data points\n",
    "# Scatter plot for training data (X_train, y_train) with blue color and marker size 30\n",
    "plt.scatter(X_train, y_train, color='blue', s=30, label='Training data')\n",
    "\n",
    "# Plot the testing data points\n",
    "# Scatter plot for testing data (X_test, y_test) with green color and marker size 30\n",
    "plt.scatter(X_test, y_test, color='green', s=30, label='Test data')\n",
    "\n",
    "# Plot the regression line\n",
    "# Line plot using the entire dataset X and predictions y_pred_line with red color, linewidth 2\n",
    "plt.plot(X, y_pred_line, color='red', linewidth=2, label='Prediction')\n",
    "\n",
    "\n",
    "# Add labels, title, and legend for clarity\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Target')\n",
    "plt.title('Linear Regression Fit')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-minute",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
